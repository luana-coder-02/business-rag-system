# Business RAG Chat System
Este proyecto es un sistema de **Generaci√≥n Aumentada por Recuperaci√≥n (RAG)** que utiliza un modelo de lenguaje grande (LLM) de **Ollama** para responder preguntas sobre anal√≠tica de datos, marketing digital y gesti√≥n de proyectos.
El sistema recupera informaci√≥n relevante de un conjunto de datos especializado para generar respuestas precisas y contextualizadas.
## üéØ Resumen del Proyecto
El objetivo es ofrecer un recurso preciso y eficiente que responda a consultas espec√≠ficas, sirviendo como una herramienta de apoyo en la toma de decisiones basada en informaci√≥n verificable.
El proyecto demuestra la capacidad de integrar un **LLM local** con una base de conocimiento externa, superando las limitaciones de la informaci√≥n pre-entrenada del modelo, **sin depender de servicios en la nube ni de una interfaz web**.
### ‚öôÔ∏è Habilidades y Caracter√≠sticas Demostradas
- **Ejecuci√≥n 100% local**: El sistema se corre directamente en la m√°quina del usuario sin necesidad de conexi√≥n externa.
- **Integraci√≥n de LLM con Ollama**: Uso de modelos open-source como **Mistral** para generar respuestas.
- **Base de datos vectorial (ChromaDB)**: Implementaci√≥n de un almac√©n persistente de embeddings para recuperaci√≥n r√°pida y eficiente.
- **Gesti√≥n de estado de sesi√≥n**: Historial de conversaci√≥n almacenado por usuario para mantener coherencia y contexto.
- **Persistencia de datos**: Sistema de logging en chat_log.jsonl para registrar las interacciones.
- **Organizaci√≥n del proyecto**: Uso de requirements.txt y una estructura modular clara para asegurar reproducibilidad y mantenimiento.
## üõ†Ô∏è Tecnolog√≠as del Stack
- Python 3.10+
- Ollama
- Mistral (modelo de lenguaje)
- ChromaDB
- Sentence Transformers
- Datasets (Hugging Face)
- JSON

## Instalaci√≥n y Uso
### Clonar el repositorio
`git clone https://github.com/tu-usuario/commercial-rag-chat.git
cd commercial-rag-chat`
### Crear y activar un entorno virtual
- `python -m venv venv`
- `source venv/bin/activate` **En Linux/Mac**
- `venv\Scripts\activate` **En Windows**
### Instalar dependencias
`pip install -r requirements.txt`
### Instalar y configurar Ollama
Descargar e instalar Ollama desde üëâ https://ollama.com/

Luego, puedes descargar el modelo (**Mistral**), as√≠:
`ollama pull mistral`
### Inicializar la base de datos vectorial
La primera vez que ejecutes el sistema, se generar√° autom√°ticamente la base de datos en `./chroma_db` e indexar√° los documentos:

`python app.py --init`
### Ejecutar el sistema RAG
Para iniciar la interacci√≥n en consola:

`python app.py`

El programa pedir√° un **user ID** y luego podr√°s hacer preguntas. Aseg√∫rate de realizar las preguntas en ingl√©s.

Para salir, simplemente escribe:

`exit`
## üîÆ Pr√≥ximas Mejoras y Hoja de Ruta
Las siguientes funcionalidades est√°n planificadas para futuras versiones, con el objetivo de hacer del sistema una herramienta a√∫n m√°s robusta y √∫til:
- **Evaluaci√≥n autom√°tica de respuestas**: Calificaci√≥n de precisi√≥n y relevancia.
- **Cambio de modelo desde configuraci√≥n**: Opci√≥n de seleccionar diferentes modelos sin modificar el c√≥digo base.
- **Exportar resultados**: Conversaciones o resultados exportables a CSV/JSON.
- **Filtros sem√°nticos**: Filtrado de documentos por categor√≠as o temas.
- **Pruebas unitarias**: Validaci√≥n de componentes de forma aislada.
## ü§ù Contacto
Si tienes alguna pregunta sobre el proyecto, te interesa mi trabajo o quieres hablar sobre una oportunidad profesional, no dudes en contactarme.

**Luana Genes**

**Email**: genesluana275@gmail.com o luanagenes275@gmail.com
